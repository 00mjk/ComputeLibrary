<!-- HTML header for doxygen 1.8.15-->
<!-- Remember to use version doxygen 1.8.15 +-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" /> <!-- Prevent indexing by search engines -->
<title>Compute Library: NEGEMMLowpOffsetContributionOutputStageKernel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="Compute Library" src="https://raw.githubusercontent.com/ARM-software/ComputeLibrary/gh-pages/ACL_logo.png" style="max-width: 100%;margin-top: 15px;margin-left: 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">21.05</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a>  </div>
  <div class="headertitle">
<div class="title">NEGEMMLowpOffsetContributionOutputStageKernel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><a class="el" href="classarm__compute_1_1_kernel.xhtml" title="Kernel class.">Kernel</a> used to add the offset contribution and perform the output stage after <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_matrix_multiply_kernel.xhtml">NEGEMMLowpMatrixMultiplyKernel</a>.  
 <a href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.h</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for NEGEMMLowpOffsetContributionOutputStageKernel:</div>
<div class="dyncontent">
<div class="center"><iframe scrolling="no" frameborder="0" src="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel__coll__graph.svg" width="239" height="202"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
<center><span class="legend">[<a target="top" href="graph_legend.xhtml">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab5656bb5b6334bdbe6e606c715872828"><td class="memItemLeft" align="right" valign="top">const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#ab5656bb5b6334bdbe6e606c715872828">name</a> () const override</td></tr>
<tr class="memdesc:ab5656bb5b6334bdbe6e606c715872828"><td class="mdescLeft">&#160;</td><td class="mdescRight">Name of the kernel.  <a href="#ab5656bb5b6334bdbe6e606c715872828">More...</a><br /></td></tr>
<tr class="separator:ab5656bb5b6334bdbe6e606c715872828"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2851f631e9660a4dd9644cb749282723"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a2851f631e9660a4dd9644cb749282723">NEGEMMLowpOffsetContributionOutputStageKernel</a> ()</td></tr>
<tr class="memdesc:a2851f631e9660a4dd9644cb749282723"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="#a2851f631e9660a4dd9644cb749282723">More...</a><br /></td></tr>
<tr class="separator:a2851f631e9660a4dd9644cb749282723"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06ecfbcd84e278efe7305e47f996befd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a06ecfbcd84e278efe7305e47f996befd">NEGEMMLowpOffsetContributionOutputStageKernel</a> (const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;)=delete</td></tr>
<tr class="memdesc:a06ecfbcd84e278efe7305e47f996befd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being copied (As this class contains pointers)  <a href="#a06ecfbcd84e278efe7305e47f996befd">More...</a><br /></td></tr>
<tr class="separator:a06ecfbcd84e278efe7305e47f996befd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbf0774f0ddecd71e3a37b11a1f76998"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#adbf0774f0ddecd71e3a37b11a1f76998">operator=</a> (const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;)=delete</td></tr>
<tr class="memdesc:adbf0774f0ddecd71e3a37b11a1f76998"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prevent instances of this class from being copied (As this class contains pointers)  <a href="#adbf0774f0ddecd71e3a37b11a1f76998">More...</a><br /></td></tr>
<tr class="separator:adbf0774f0ddecd71e3a37b11a1f76998"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f3daabb9fa6cc420456de1a25de6200"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a1f3daabb9fa6cc420456de1a25de6200">NEGEMMLowpOffsetContributionOutputStageKernel</a> (<a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&amp;)=default</td></tr>
<tr class="memdesc:a1f3daabb9fa6cc420456de1a25de6200"><td class="mdescLeft">&#160;</td><td class="mdescRight">Allow instances of this class to be moved.  <a href="#a1f3daabb9fa6cc420456de1a25de6200">More...</a><br /></td></tr>
<tr class="separator:a1f3daabb9fa6cc420456de1a25de6200"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5b5d293aabb6e876154c73bdf1cffac"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#af5b5d293aabb6e876154c73bdf1cffac">operator=</a> (<a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&amp;)=default</td></tr>
<tr class="memdesc:af5b5d293aabb6e876154c73bdf1cffac"><td class="mdescLeft">&#160;</td><td class="mdescRight">Allow instances of this class to be moved.  <a href="#af5b5d293aabb6e876154c73bdf1cffac">More...</a><br /></td></tr>
<tr class="separator:af5b5d293aabb6e876154c73bdf1cffac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c2dbd165be7ed0e29c61bdd49c8523a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a6c2dbd165be7ed0e29c61bdd49c8523a">~NEGEMMLowpOffsetContributionOutputStageKernel</a> ()=default</td></tr>
<tr class="memdesc:a6c2dbd165be7ed0e29c61bdd49c8523a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default destructor.  <a href="#a6c2dbd165be7ed0e29c61bdd49c8523a">More...</a><br /></td></tr>
<tr class="separator:a6c2dbd165be7ed0e29c61bdd49c8523a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97ebe5c0444a53d58d9b9f079ebe2d0f"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a97ebe5c0444a53d58d9b9f079ebe2d0f">configure</a> (const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *mm_result, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *vector_sum_col, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *vector_sum_row, const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *bias, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *output, int32_t k, int32_t a_offset, int32_t b_offset, <a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a> output_stage)</td></tr>
<tr class="memdesc:a97ebe5c0444a53d58d9b9f079ebe2d0f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialise the kernel's input and output.  <a href="#a97ebe5c0444a53d58d9b9f079ebe2d0f">More...</a><br /></td></tr>
<tr class="separator:a97ebe5c0444a53d58d9b9f079ebe2d0f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a112b35dd205c62ea6ed1447ef226da82"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a112b35dd205c62ea6ed1447ef226da82">run</a> (const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;<a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;info) override</td></tr>
<tr class="memdesc:a112b35dd205c62ea6ed1447ef226da82"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute the kernel on the passed window.  <a href="#a112b35dd205c62ea6ed1447ef226da82">More...</a><br /></td></tr>
<tr class="separator:a112b35dd205c62ea6ed1447ef226da82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_c_p_p_kernel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml">ICPPKernel</a></td></tr>
<tr class="memitem:a033d17a97e07cea7fe83eefcf23540f6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a033d17a97e07cea7fe83eefcf23540f6">~ICPPKernel</a> ()=default</td></tr>
<tr class="memdesc:a033d17a97e07cea7fe83eefcf23540f6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default destructor.  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a033d17a97e07cea7fe83eefcf23540f6">More...</a><br /></td></tr>
<tr class="separator:a033d17a97e07cea7fe83eefcf23540f6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92fc66203d7affe26cbe70194a154895 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a92fc66203d7affe26cbe70194a154895">run_nd</a> (const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;<a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;info, const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;thread_locator)</td></tr>
<tr class="memdesc:a92fc66203d7affe26cbe70194a154895 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">legacy compatibility layer for implemantions which do not support thread_locator In these cases we simply narrow the interface down the legacy version  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a92fc66203d7affe26cbe70194a154895">More...</a><br /></td></tr>
<tr class="separator:a92fc66203d7affe26cbe70194a154895 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b8ef149ef3b6ca5e548473916f95cd6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a6b8ef149ef3b6ca5e548473916f95cd6">run_op</a> (<a class="el" href="classarm__compute_1_1_i_tensor_pack.xhtml">ITensorPack</a> &amp;tensors, const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;<a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;info)</td></tr>
<tr class="memdesc:a6b8ef149ef3b6ca5e548473916f95cd6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execute the kernel on the passed window.  <a href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a6b8ef149ef3b6ca5e548473916f95cd6">More...</a><br /></td></tr>
<tr class="separator:a6b8ef149ef3b6ca5e548473916f95cd6 inherit pub_methods_classarm__compute_1_1_i_c_p_p_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classarm__compute_1_1_i_kernel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classarm__compute_1_1_i_kernel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classarm__compute_1_1_i_kernel.xhtml">IKernel</a></td></tr>
<tr class="memitem:a7250cb8cbaa4104a93a2d77155085507 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a7250cb8cbaa4104a93a2d77155085507">IKernel</a> ()</td></tr>
<tr class="memdesc:a7250cb8cbaa4104a93a2d77155085507 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="classarm__compute_1_1_i_kernel.xhtml#a7250cb8cbaa4104a93a2d77155085507">More...</a><br /></td></tr>
<tr class="separator:a7250cb8cbaa4104a93a2d77155085507 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a341b60d15a5e12a5b8f3825194dd3b12 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a341b60d15a5e12a5b8f3825194dd3b12">~IKernel</a> ()=default</td></tr>
<tr class="memdesc:a341b60d15a5e12a5b8f3825194dd3b12 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="classarm__compute_1_1_i_kernel.xhtml#a341b60d15a5e12a5b8f3825194dd3b12">More...</a><br /></td></tr>
<tr class="separator:a341b60d15a5e12a5b8f3825194dd3b12 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0466ee6ce6552c87595f0e88e73eeb1b inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a0466ee6ce6552c87595f0e88e73eeb1b">is_parallelisable</a> () const</td></tr>
<tr class="memdesc:a0466ee6ce6552c87595f0e88e73eeb1b inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Indicates whether or not the kernel is parallelisable.  <a href="classarm__compute_1_1_i_kernel.xhtml#a0466ee6ce6552c87595f0e88e73eeb1b">More...</a><br /></td></tr>
<tr class="separator:a0466ee6ce6552c87595f0e88e73eeb1b inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b3a97ba5dded504a2f2261c078493dd inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="structarm__compute_1_1_border_size.xhtml">BorderSize</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a4b3a97ba5dded504a2f2261c078493dd">border_size</a> () const</td></tr>
<tr class="memdesc:a4b3a97ba5dded504a2f2261c078493dd inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">The size of the border for that kernel.  <a href="classarm__compute_1_1_i_kernel.xhtml#a4b3a97ba5dded504a2f2261c078493dd">More...</a><br /></td></tr>
<tr class="separator:a4b3a97ba5dded504a2f2261c078493dd inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad34a46f53686c12a5c5e717cc9617fb6 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a> () const</td></tr>
<tr class="memdesc:ad34a46f53686c12a5c5e717cc9617fb6 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">The maximum window the kernel can be executed on.  <a href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">More...</a><br /></td></tr>
<tr class="separator:ad34a46f53686c12a5c5e717cc9617fb6 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32ab3ad0302912c7da52204042727a44 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a32ab3ad0302912c7da52204042727a44">is_window_configured</a> () const</td></tr>
<tr class="memdesc:a32ab3ad0302912c7da52204042727a44 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function to check if the embedded window of this kernel has been configured.  <a href="classarm__compute_1_1_i_kernel.xhtml#a32ab3ad0302912c7da52204042727a44">More...</a><br /></td></tr>
<tr class="separator:a32ab3ad0302912c7da52204042727a44 inherit pub_methods_classarm__compute_1_1_i_kernel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a6296f2754011b2221b343ccedfc0ba35"><td class="memItemLeft" align="right" valign="top">static <a class="el" href="classarm__compute_1_1_status.xhtml">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml#a6296f2754011b2221b343ccedfc0ba35">validate</a> (const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *mm_result, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *vector_sum_col, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *vector_sum_row, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *bias, const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *output, int32_t a_offset, int32_t b_offset, <a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a> output_stage)</td></tr>
<tr class="memdesc:a6296f2754011b2221b343ccedfc0ba35"><td class="mdescLeft">&#160;</td><td class="mdescRight">Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a>.  <a href="#a6296f2754011b2221b343ccedfc0ba35">More...</a><br /></td></tr>
<tr class="separator:a6296f2754011b2221b343ccedfc0ba35"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p><a class="el" href="classarm__compute_1_1_kernel.xhtml" title="Kernel class.">Kernel</a> used to add the offset contribution and perform the output stage after <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_matrix_multiply_kernel.xhtml">NEGEMMLowpMatrixMultiplyKernel</a>. </p>
<p>The computation is performed in-place</p>
<p>This kernel takes a final int32 accumulator value (the output of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_matrix_multiply_kernel.xhtml">NEGEMMLowpMatrixMultiplyKernel</a>), and adds to it the offset contribution of matrix A and matrix B in-place.</p>
<p>The output stage can perform either QuantizeDownInt32ToUint8Scale or QuantizeDownInt32ToUint8ScaleByFixedPoint for Uint8. The output stage can perform either QuantizeDownInt32ToInt8Scale or QuantizeDownInt32ToInt8ScaleByFixedPoint for Int8.</p>
<p>For QuantizeDownInt32ToUint8Scale/QuantizeDownInt32ToInt8Scale the final result is:</p>
<p>((mm_result'[i][k] + result_offset) * result_mult_int) &gt;&gt; result_shift</p>
<p>For QuantizeDownInt32ToUint8ScaleByFixedPoint/QuantizeDownInt32ToInt8ScaleByFixedPoint the final result is:</p>
<p>(FixedPointMul(mm_result'[i][k], result_fixedpoint_multiplier) &gt;&gt; result_shift) + result_offset_after_shift</p>
<p>where FixedPointMul(x, y) is the nearest integer to the following mathematical expression, evaluated without overflow or intermediate rounding:</p>
<p>(x * y) / 2^31</p>
<p>and mm_result'[i][k] = mm_result[i][k] + (vector_sum_col[k] * a_offset) + (vector_sum_row[i] * b_offset) + (a_offset * b_offset * k) </p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml#l00062">62</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a2851f631e9660a4dd9644cb749282723"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2851f631e9660a4dd9644cb749282723">&#9670;&nbsp;</a></span>NEGEMMLowpOffsetContributionOutputStageKernel() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00856">856</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160;    : _vector_sum_col(<span class="keyword">nullptr</span>), _vector_sum_row(<span class="keyword">nullptr</span>), _bias(<span class="keyword">nullptr</span>), _mm_result(<span class="keyword">nullptr</span>), _output(<span class="keyword">nullptr</span>), _a_offset(0), _b_offset(0), _k_offset(0), _slide_vector_sum_col(<span class="keyword">true</span>),</div><div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;      _output_stage(GEMMLowpOutputStageInfo())</div><div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;</div><div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;{</div><div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;}</div></div><!-- fragment -->
</div>
</div>
<a id="a06ecfbcd84e278efe7305e47f996befd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06ecfbcd84e278efe7305e47f996befd">&#9670;&nbsp;</a></span>NEGEMMLowpOffsetContributionOutputStageKernel() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="a1f3daabb9fa6cc420456de1a25de6200"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f3daabb9fa6cc420456de1a25de6200">&#9670;&nbsp;</a></span>NEGEMMLowpOffsetContributionOutputStageKernel() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Allow instances of this class to be moved. </p>

</div>
</div>
<a id="a6c2dbd165be7ed0e29c61bdd49c8523a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c2dbd165be7ed0e29c61bdd49c8523a">&#9670;&nbsp;</a></span>~NEGEMMLowpOffsetContributionOutputStageKernel()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">~<a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Default destructor. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a97ebe5c0444a53d58d9b9f079ebe2d0f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97ebe5c0444a53d58d9b9f079ebe2d0f">&#9670;&nbsp;</a></span>configure()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void configure </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>mm_result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_row</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_i_tensor.xhtml">ITensor</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>a_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>b_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a>&#160;</td>
          <td class="paramname"><em>output_stage</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialise the kernel's input and output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">mm_result</td><td>Input tensor containing the result of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_matrix_multiply_kernel.xhtml">NEGEMMLowpMatrixMultiplyKernel</a>. Data type supported: S32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_sum_col</td><td>Input row-vector of sums of all the entries in each column of matrix B. Note: vector_sum_col can be a nullptr in case a_offset = 0. Data type supported: same as <code>mm_result</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_sum_row</td><td>Input row-vector of sums of all the entries in each row of matrix A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Biases tensor. Only shared biases supported and it can be a nullptr if the addition of biases is not required. Biases are 1D tensor with dimensions [OFM]. Data type supported: Same as <code>mm_result</code>. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Output tensor containing the final quantized result. Data type supported: QASYMM8/QASYMM8_SIGNED </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">k</td><td>Number of matrix A columns or Matrix B rows </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">a_offset</td><td>Offset to be added to each element of the matrix A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">b_offset</td><td>Offset to be added to each element of the matrix B. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_stage</td><td>GEMMLowp output stage info, providing the type of quantization and the necessary parameters. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00863">863</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;{</div><div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;    <span class="comment">// Perform validate step</span></div><div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a>(mm_result, output);</div><div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;</div><div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;    <a class="code" href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a>(<a class="code" href="namespacearm__compute.xhtml#a40e33693e83cee949a89811e7dabbd3c">validate_arguments</a>(mm_result-&gt;info(),</div><div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;                                                  vector_sum_col != <span class="keyword">nullptr</span> ? vector_sum_col-&gt;info() : <span class="keyword">nullptr</span>, <span class="comment">// NOLINT</span></div><div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;                                                  vector_sum_row != <span class="keyword">nullptr</span> ? vector_sum_row-&gt;info() : <span class="keyword">nullptr</span>, <span class="comment">// NOLINT</span></div><div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;                                                  bias != <span class="keyword">nullptr</span> ? bias-&gt;info() : <span class="keyword">nullptr</span>,                     <span class="comment">// NOLINT</span></div><div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;                                                  output-&gt;info(), a_offset, b_offset, output_stage));           <span class="comment">// NOLINT</span></div><div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;</div><div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;    _vector_sum_col = vector_sum_col;</div><div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160;    _vector_sum_row = vector_sum_row;</div><div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;    _bias           = bias;</div><div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;    _mm_result      = mm_result;</div><div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160;    _output         = output;</div><div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;    _a_offset       = a_offset;</div><div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;    _b_offset       = b_offset;</div><div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;    _k_offset       = a_offset * b_offset * k;</div><div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;    _output_stage   = output_stage;</div><div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;</div><div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;    <span class="comment">// If a_offset == 0, vector_sum_col can be a nullptr</span></div><div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;    <span class="keywordflow">if</span>(a_offset != 0)</div><div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;    {</div><div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160;        <span class="comment">// Check if vector_sum_col_shape should be slidden or not</span></div><div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;        <span class="comment">// Don&#39;t slide vector_sum_col_shape along the y dimension if vector_sum_col_shape has just 1 dimension and vector_sum_row_shape more than 1</span></div><div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160;        <span class="comment">// This scenario can happen when the the matrix multiplication is used to perform a convolution operation</span></div><div class="line"><a name="l00893"></a><span class="lineno">  893</span>&#160;        _slide_vector_sum_col = vector_sum_col-&gt;info()-&gt;tensor_shape().num_dimensions() &gt; 1;</div><div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;    }</div><div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;</div><div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;    <span class="comment">// Configure kernel window</span></div><div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;    <span class="keyword">auto</span> win_config = validate_and_configure_window(mm_result-&gt;info(), output-&gt;info());</div><div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;    <a class="code" href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a>(win_config.first);</div><div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;    INEKernel::configure(win_config.second);</div><div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;}</div><div class="ttc" id="_error_8h_xhtml_a938dcd406ce611ef5345ad2531cdb948"><div class="ttname"><a href="_error_8h.xhtml#a938dcd406ce611ef5345ad2531cdb948">ARM_COMPUTE_ERROR_THROW_ON</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_THROW_ON(status)</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00455">Error.h:455</a></div></div>
<div class="ttc" id="namespacearm__compute_xhtml_a40e33693e83cee949a89811e7dabbd3c"><div class="ttname"><a href="namespacearm__compute.xhtml#a40e33693e83cee949a89811e7dabbd3c">arm_compute::validate_arguments</a></div><div class="ttdeci">Status validate_arguments(const ITensorInfo *input, const ITensorInfo *bias, const ITensorInfo *output, const GEMMLowpOutputStageInfo *output_stage)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_lowp_quantize_down_int32_scale_kernel_8cpp_source.xhtml#l00045">NEGEMMLowpQuantizeDownInt32ScaleKernel.cpp:45</a></div></div>
<div class="ttc" id="arm__compute_2core_2_validate_8h_xhtml_a921b705e9e3e0fe928928447869e62a5"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_NULLPTR(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00157">Validate.h:157</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00157">ARM_COMPUTE_ERROR_ON_NULLPTR</a>, <a class="el" href="_error_8h_source.xhtml#l00455">ARM_COMPUTE_ERROR_THROW_ON</a>, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">ITensor::info()</a>, <a class="el" href="_dimensions_8h_source.xhtml#l00143">Dimensions&lt; T &gt;::num_dimensions()</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">ITensorInfo::tensor_shape()</a>, and <a class="el" href="_n_e_g_e_m_m_lowp_quantize_down_int32_scale_kernel_8cpp_source.xhtml#l00045">arm_compute::validate_arguments()</a>.</p>

</div>
</div>
<a id="ab5656bb5b6334bdbe6e606c715872828"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab5656bb5b6334bdbe6e606c715872828">&#9670;&nbsp;</a></span>name()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const char* name </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Name of the kernel. </p>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="classarm__compute_1_1_kernel.xhtml" title="Kernel class.">Kernel</a> name </dd></dl>

<p>Implements <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#a1a30ad8f276a2310571c36239554831a">ICPPKernel</a>.</p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml#l00065">65</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.h</a>.</p>
<div class="fragment"><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    {</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;        <span class="keywordflow">return</span> <span class="stringliteral">&quot;NEGEMMLowpOffsetContributionOutputStageKernel&quot;</span>;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    }</div></div><!-- fragment -->
</div>
</div>
<a id="adbf0774f0ddecd71e3a37b11a1f76998"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adbf0774f0ddecd71e3a37b11a1f76998">&#9670;&nbsp;</a></span>operator=() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a>&amp; operator= </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">delete</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Prevent instances of this class from being copied (As this class contains pointers) </p>

</div>
</div>
<a id="af5b5d293aabb6e876154c73bdf1cffac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5b5d293aabb6e876154c73bdf1cffac">&#9670;&nbsp;</a></span>operator=() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a>&amp; operator= </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a> &amp;&amp;&#160;</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Allow instances of this class to be moved. </p>

</div>
</div>
<a id="a112b35dd205c62ea6ed1447ef226da82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a112b35dd205c62ea6ed1447ef226da82">&#9670;&nbsp;</a></span>run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void run </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_window.xhtml">Window</a> &amp;&#160;</td>
          <td class="paramname"><em>window</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structarm__compute_1_1_thread_info.xhtml">ThreadInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Execute the kernel on the passed window. </p>
<dl class="section warning"><dt>Warning</dt><dd>If <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#a0466ee6ce6552c87595f0e88e73eeb1b" title="Indicates whether or not the kernel is parallelisable.">is_parallelisable()</a> returns false then the passed window must be equal to <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6" title="The maximum window the kernel can be executed on.">window()</a></dd></dl>
<dl class="section note"><dt>Note</dt><dd>The window has to be a region within the window returned by the <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6" title="The maximum window the kernel can be executed on.">window()</a> method</dd>
<dd>
The width of the window has to be a multiple of <a class="el" href="_c_l_im2_col_kernel_8cpp.xhtml#a4e45c1f5e4280813a78a77dda71d8799">num_elems_processed_per_iteration()</a>.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">window</td><td>Region on which to execute the kernel. (Must be a region of the window returned by <a class="el" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6" title="The maximum window the kernel can be executed on.">window()</a>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">info</td><td>Info about executing thread and CPU. </td></tr>
  </table>
  </dd>
</dl>

<p>Reimplemented from <a class="el" href="classarm__compute_1_1_i_c_p_p_kernel.xhtml#ad6586f7a2dd64942f59b8c408643a0ea">ICPPKernel</a>.</p>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00912">912</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;{</div><div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;    <a class="code" href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a>(<a class="code" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">info</a>);</div><div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a1b35b0d258183cf9ef36adf684d0b88c">ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL</a>(<span class="keyword">this</span>);</div><div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a6eb9ce82815fe429250189da7592ba75">ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW</a>(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">INEKernel::window</a>(), <a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>);</div><div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;</div><div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;    PixelValue type_min{};</div><div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;    PixelValue type_max{};</div><div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;    std::tie(type_min, type_max) = <a class="code" href="namespacearm__compute.xhtml#ae69217acf0f0b5d4de030a09ad50a0bc">get_min_max</a>(_output-&gt;<a class="code" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">info</a>()-&gt;<a class="code" href="classarm__compute_1_1_i_tensor_info.xhtml#a7cfb31af63202568efef5214acfbf3ba">data_type</a>());</div><div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;    int32_t type_min_int = type_min.get&lt;int32_t&gt;();</div><div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;    int32_t type_max_int = type_max.get&lt;int32_t&gt;();</div><div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;</div><div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> reinterpret_as_3d = _vector_sum_row != <span class="keyword">nullptr</span></div><div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;                                   &amp;&amp; _mm_result-&gt;<a class="code" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">info</a>()-&gt;<a class="code" href="classarm__compute_1_1_i_tensor_info.xhtml#a1f4e725b8e1ea36b30e09dc08ae6961d">num_dimensions</a>() &gt; 1</div><div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;                                   &amp;&amp; _mm_result-&gt;<a class="code" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">info</a>()-&gt;<a class="code" href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">tensor_shape</a>().<a class="code" href="classarm__compute_1_1_dimensions.xhtml#ac4a1050be02b20b3f791b9a483f3abe2">y</a>() != _vector_sum_row-&gt;<a class="code" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">info</a>()-&gt;<a class="code" href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">tensor_shape</a>().<a class="code" href="classarm__compute_1_1_dimensions.xhtml#aa87f8fc26981b0f3228a78c83b95b802">x</a>();</div><div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;</div><div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_bounded_relu = !(_output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a155d27c75f14a82a74e5039c9657c8eb">gemmlowp_min_bound</a> &lt;= type_min_int &amp;&amp; _output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6db94040329f1dedcd348ec7de072e2a">gemmlowp_max_bound</a> &gt;= type_max_int);</div><div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160;</div><div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;    <span class="comment">// Check if we need to perform fixed point requantization</span></div><div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_fixed_point = _output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6e019ad85979fd73c74f97e5483faf35">type</a> != <a class="code" href="namespacearm__compute.xhtml#a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b">GEMMLowpOutputStageType::QUANTIZE_DOWN</a>;</div><div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160;</div><div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;    <span class="comment">// Check if symmetric per-channel execution</span></div><div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_signed = _output-&gt;<a class="code" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">info</a>()-&gt;<a class="code" href="classarm__compute_1_1_i_tensor_info.xhtml#a7cfb31af63202568efef5214acfbf3ba">data_type</a>() == <a class="code" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9">DataType::QASYMM8_SIGNED</a>;</div><div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;</div><div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;    <span class="comment">// Check if symmetric per-channel execution</span></div><div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">bool</span> is_symm = _output_stage.<a class="code" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a94e1801be6c3d9d6645c694d7e280cda">is_quantized_per_channel</a>;</div><div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;</div><div class="line"><a name="l00939"></a><span class="lineno">  939</span>&#160;    <span class="keywordflow">if</span>(is_symm)</div><div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160;    {</div><div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;        run_offset_contribution_output_stage_symm(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, _mm_result, _vector_sum_col, _vector_sum_row, _bias, _output, _a_offset, _b_offset, _k_offset, _slide_vector_sum_col, _output_stage,</div><div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;                                                  reinterpret_as_3d, is_bounded_relu, is_fixed_point);</div><div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160;    }</div><div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;    <span class="keywordflow">else</span></div><div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;    {</div><div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;        <span class="keywordflow">if</span>(is_signed)</div><div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;        {</div><div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160;            run_offset_contribution_output_stage&lt;int8_t&gt;(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, _mm_result, _vector_sum_col, _vector_sum_row, _bias, _output, _a_offset, _b_offset, _k_offset, _slide_vector_sum_col, _output_stage,</div><div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;                                                         reinterpret_as_3d, is_bounded_relu, is_fixed_point);</div><div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;        }</div><div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160;        <span class="keywordflow">else</span></div><div class="line"><a name="l00952"></a><span class="lineno">  952</span>&#160;        {</div><div class="line"><a name="l00953"></a><span class="lineno">  953</span>&#160;            run_offset_contribution_output_stage&lt;uint8_t&gt;(<a class="code" href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">window</a>, _mm_result, _vector_sum_col, _vector_sum_row, _bias, _output, _a_offset, _b_offset, _k_offset, _slide_vector_sum_col, _output_stage,</div><div class="line"><a name="l00954"></a><span class="lineno">  954</span>&#160;                                                          reinterpret_as_3d, is_bounded_relu, is_fixed_point);</div><div class="line"><a name="l00955"></a><span class="lineno">  955</span>&#160;        }</div><div class="line"><a name="l00956"></a><span class="lineno">  956</span>&#160;    }</div><div class="line"><a name="l00957"></a><span class="lineno">  957</span>&#160;}</div><div class="ttc" id="classarm__compute_1_1_i_tensor_info_xhtml_a1f4e725b8e1ea36b30e09dc08ae6961d"><div class="ttname"><a href="classarm__compute_1_1_i_tensor_info.xhtml#a1f4e725b8e1ea36b30e09dc08ae6961d">arm_compute::ITensorInfo::num_dimensions</a></div><div class="ttdeci">virtual size_t num_dimensions() const =0</div><div class="ttdoc">The number of dimensions of the tensor (rank)</div></div>
<div class="ttc" id="classarm__compute_1_1_i_kernel_xhtml_ad34a46f53686c12a5c5e717cc9617fb6"><div class="ttname"><a href="classarm__compute_1_1_i_kernel.xhtml#ad34a46f53686c12a5c5e717cc9617fb6">arm_compute::IKernel::window</a></div><div class="ttdeci">const Window &amp; window() const</div><div class="ttdoc">The maximum window the kernel can be executed on.</div><div class="ttdef"><b>Definition:</b> <a href="_i_kernel_8cpp_source.xhtml#l00028">IKernel.cpp:28</a></div></div>
<div class="ttc" id="classarm__compute_1_1_i_tensor_info_xhtml_a7cfb31af63202568efef5214acfbf3ba"><div class="ttname"><a href="classarm__compute_1_1_i_tensor_info.xhtml#a7cfb31af63202568efef5214acfbf3ba">arm_compute::ITensorInfo::data_type</a></div><div class="ttdeci">virtual DataType data_type() const =0</div><div class="ttdoc">Data type used for each element of the tensor.</div></div>
<div class="ttc" id="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a6db94040329f1dedcd348ec7de072e2a"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6db94040329f1dedcd348ec7de072e2a">arm_compute::GEMMLowpOutputStageInfo::gemmlowp_max_bound</a></div><div class="ttdeci">int32_t gemmlowp_max_bound</div><div class="ttdoc">GEMMLowp max value used to saturate down the output result before converting back to QASYMM8.</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_types_8h_source.xhtml#l01894">Types.h:1894</a></div></div>
<div class="ttc" id="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a6e019ad85979fd73c74f97e5483faf35"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a6e019ad85979fd73c74f97e5483faf35">arm_compute::GEMMLowpOutputStageInfo::type</a></div><div class="ttdeci">GEMMLowpOutputStageType type</div><div class="ttdoc">GEMMLowp output stage type.</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_types_8h_source.xhtml#l01889">Types.h:1889</a></div></div>
<div class="ttc" id="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a94e1801be6c3d9d6645c694d7e280cda"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a94e1801be6c3d9d6645c694d7e280cda">arm_compute::GEMMLowpOutputStageInfo::is_quantized_per_channel</a></div><div class="ttdeci">bool is_quantized_per_channel</div><div class="ttdoc">GEMMLowp quantized per-channel flag.</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_types_8h_source.xhtml#l01898">Types.h:1898</a></div></div>
<div class="ttc" id="classarm__compute_1_1_dimensions_xhtml_aa87f8fc26981b0f3228a78c83b95b802"><div class="ttname"><a href="classarm__compute_1_1_dimensions.xhtml#aa87f8fc26981b0f3228a78c83b95b802">arm_compute::Dimensions::x</a></div><div class="ttdeci">T x() const</div><div class="ttdoc">Alias to access the size of the first dimension.</div><div class="ttdef"><b>Definition:</b> <a href="_dimensions_8h_source.xhtml#l00087">Dimensions.h:87</a></div></div>
<div class="ttc" id="_error_8h_xhtml_a6dc630a6ae9cc063b3924bcea8dee9d6"><div class="ttname"><a href="_error_8h.xhtml#a6dc630a6ae9cc063b3924bcea8dee9d6">ARM_COMPUTE_UNUSED</a></div><div class="ttdeci">#define ARM_COMPUTE_UNUSED(...)</div><div class="ttdoc">To avoid unused variables warnings.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00152">Error.h:152</a></div></div>
<div class="ttc" id="classarm__compute_1_1_i_tensor_info_xhtml_a7c66505457d00ece3aa4b34cab80757d"><div class="ttname"><a href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">arm_compute::ITensorInfo::tensor_shape</a></div><div class="ttdeci">virtual const TensorShape &amp; tensor_shape() const =0</div><div class="ttdoc">Size for each dimension of the tensor.</div></div>
<div class="ttc" id="classarm__compute_1_1_i_tensor_xhtml_a0e95dc1e53c361348314873b168ae237"><div class="ttname"><a href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">arm_compute::ITensor::info</a></div><div class="ttdeci">virtual ITensorInfo * info() const =0</div><div class="ttdoc">Interface to be implemented by the child class to return the tensor's metadata.</div></div>
<div class="ttc" id="namespacearm__compute_xhtml_a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b"><div class="ttname"><a href="namespacearm__compute.xhtml#a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b">arm_compute::GEMMLowpOutputStageType::QUANTIZE_DOWN</a></div><div class="ttdoc">Quantize using an integer multiplication.</div></div>
<div class="ttc" id="arm__compute_2core_2_validate_8h_xhtml_a1b35b0d258183cf9ef36adf684d0b88c"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a1b35b0d258183cf9ef36adf684d0b88c">ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL(k)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00915">Validate.h:915</a></div></div>
<div class="ttc" id="namespacearm__compute_1_1test_1_1validation_xhtml_ac57b92957968088a392021cac1d2076b"><div class="ttname"><a href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a></div><div class="ttdeci">ScaleKernelInfo info(interpolation_policy, default_border_mode, PixelValue(), sampling_policy, false)</div></div>
<div class="ttc" id="classarm__compute_1_1_dimensions_xhtml_ac4a1050be02b20b3f791b9a483f3abe2"><div class="ttname"><a href="classarm__compute_1_1_dimensions.xhtml#ac4a1050be02b20b3f791b9a483f3abe2">arm_compute::Dimensions::y</a></div><div class="ttdeci">T y() const</div><div class="ttdoc">Alias to access the size of the second dimension.</div><div class="ttdef"><b>Definition:</b> <a href="_dimensions_8h_source.xhtml#l00092">Dimensions.h:92</a></div></div>
<div class="ttc" id="namespacearm__compute_xhtml_ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9"><div class="ttname"><a href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9">arm_compute::DataType::QASYMM8_SIGNED</a></div><div class="ttdoc">quantized, asymmetric fixed-point 8-bit number signed</div></div>
<div class="ttc" id="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info_xhtml_a155d27c75f14a82a74e5039c9657c8eb"><div class="ttname"><a href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml#a155d27c75f14a82a74e5039c9657c8eb">arm_compute::GEMMLowpOutputStageInfo::gemmlowp_min_bound</a></div><div class="ttdeci">int32_t gemmlowp_min_bound</div><div class="ttdoc">GEMMLowp min value used to saturate down the output result before converting back to QASYMM8.</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_types_8h_source.xhtml#l01893">Types.h:1893</a></div></div>
<div class="ttc" id="namespacearm__compute_xhtml_ae69217acf0f0b5d4de030a09ad50a0bc"><div class="ttname"><a href="namespacearm__compute.xhtml#ae69217acf0f0b5d4de030a09ad50a0bc">arm_compute::get_min_max</a></div><div class="ttdeci">std::tuple&lt; PixelValue, PixelValue &gt; get_min_max(DataType dt)</div><div class="ttdoc">Compute the mininum and maximum values a data type can take.</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_utils_8h_source.xhtml#l00564">Utils.h:564</a></div></div>
<div class="ttc" id="arm__compute_2core_2_validate_8h_xhtml_a6eb9ce82815fe429250189da7592ba75"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a6eb9ce82815fe429250189da7592ba75">ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW(f, s)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00201">Validate.h:201</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00201">ARM_COMPUTE_ERROR_ON_INVALID_SUBWINDOW</a>, <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00915">ARM_COMPUTE_ERROR_ON_UNCONFIGURED_KERNEL</a>, <a class="el" href="_error_8h_source.xhtml#l00152">ARM_COMPUTE_UNUSED</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a7cfb31af63202568efef5214acfbf3ba">ITensorInfo::data_type()</a>, <a class="el" href="arm__compute_2core_2_types_8h_source.xhtml#l01894">GEMMLowpOutputStageInfo::gemmlowp_max_bound</a>, <a class="el" href="arm__compute_2core_2_types_8h_source.xhtml#l01893">GEMMLowpOutputStageInfo::gemmlowp_min_bound</a>, <a class="el" href="arm__compute_2core_2_utils_8h_source.xhtml#l00564">arm_compute::get_min_max()</a>, <a class="el" href="classarm__compute_1_1_i_tensor.xhtml#a0e95dc1e53c361348314873b168ae237">ITensor::info()</a>, <a class="el" href="namespacearm__compute_1_1test_1_1validation.xhtml#ac57b92957968088a392021cac1d2076b">arm_compute::test::validation::info</a>, <a class="el" href="arm__compute_2core_2_types_8h_source.xhtml#l01898">GEMMLowpOutputStageInfo::is_quantized_per_channel</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a1f4e725b8e1ea36b30e09dc08ae6961d">ITensorInfo::num_dimensions()</a>, <a class="el" href="namespacearm__compute.xhtml#ad8ed01ff3ff33333d8e19db4d2818bb6a329f5d0c4b0c80e3474951d2c4435dd9">arm_compute::QASYMM8_SIGNED</a>, <a class="el" href="namespacearm__compute.xhtml#a5558e2cc22f7f4771653d992c8ad8864a079e2ddc95b344b5cb0188bed9a80d8b">arm_compute::QUANTIZE_DOWN</a>, <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml#a7c66505457d00ece3aa4b34cab80757d">ITensorInfo::tensor_shape()</a>, <a class="el" href="arm__compute_2core_2_types_8h_source.xhtml#l01889">GEMMLowpOutputStageInfo::type</a>, <a class="el" href="_i_kernel_8cpp_source.xhtml#l00028">IKernel::window()</a>, <a class="el" href="_dimensions_8h_source.xhtml#l00087">Dimensions&lt; T &gt;::x()</a>, and <a class="el" href="_dimensions_8h_source.xhtml#l00092">Dimensions&lt; T &gt;::y()</a>.</p>

</div>
</div>
<a id="a6296f2754011b2221b343ccedfc0ba35"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6296f2754011b2221b343ccedfc0ba35">&#9670;&nbsp;</a></span>validate()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarm__compute_1_1_status.xhtml">Status</a> validate </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>mm_result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_col</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>vector_sum_row</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classarm__compute_1_1_i_tensor_info.xhtml">ITensorInfo</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>a_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>b_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structarm__compute_1_1_g_e_m_m_lowp_output_stage_info.xhtml">GEMMLowpOutputStageInfo</a>&#160;</td>
          <td class="paramname"><em>output_stage</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Static function to check if given info will lead to a valid configuration of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">mm_result</td><td>Input tensor info containing the result of <a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_matrix_multiply_kernel.xhtml">NEGEMMLowpMatrixMultiplyKernel</a>. Data type supported: S32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_sum_col</td><td><a class="el" href="classarm__compute_1_1_tensor.xhtml" title="Basic implementation of the tensor interface.">Tensor</a> info for the input row-vector of sums of all the entries in each column of matrix B. Note: vector_sum_col can be a nullptr in case a_offset = 0. Data type supported: same as <code>mm_result</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_sum_row</td><td><a class="el" href="classarm__compute_1_1_tensor.xhtml" title="Basic implementation of the tensor interface.">Tensor</a> info for the input row-vector of sums of all the entries in each row of matrix A. Note: vector_sum_row can be a nullptr in case b_offset = 0. Data type supported: same as <code>mm_result</code> </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>Biases tensor info. Only shared biases supported and it can be a nullptr if the addition of biases is not required. Biases are 1D tensor with dimensions [OFM]. Data type supported: Same as <code>mm_result</code>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output</td><td>Output tensor info containing the final quantized result. Data type supported: QASYMM8/QASYMM8_SIGNED </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">a_offset</td><td>Offset to be added to each element of the matrix A. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">b_offset</td><td>Offset to be added to each element of the matrix B. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_stage</td><td>GEMMLowp output stage info, providing the type of quantization and the necessary parameters.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>a status </dd></dl>

<p class="definition">Definition at line <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml#l00902">902</a> of file <a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;{</div><div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;    <a class="code" href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a>(mm_result, output);</div><div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;    <a class="code" href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a>(<a class="code" href="namespacearm__compute.xhtml#a40e33693e83cee949a89811e7dabbd3c">validate_arguments</a>(mm_result, vector_sum_col, vector_sum_row, bias, output, a_offset, b_offset, output_stage));</div><div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;    <a class="code" href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a>(validate_and_configure_window(mm_result-&gt;clone().get(), output-&gt;clone().get()).first);</div><div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;    <span class="keywordflow">return</span> Status{};</div><div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;}</div><div class="ttc" id="_error_8h_xhtml_a8a1e1c105f0bdaf37db408c7cfcb77a4"><div class="ttname"><a href="_error_8h.xhtml#a8a1e1c105f0bdaf37db408c7cfcb77a4">ARM_COMPUTE_RETURN_ON_ERROR</a></div><div class="ttdeci">#define ARM_COMPUTE_RETURN_ON_ERROR(status)</div><div class="ttdoc">Checks if a status contains an error and returns it.</div><div class="ttdef"><b>Definition:</b> <a href="_error_8h_source.xhtml#l00204">Error.h:204</a></div></div>
<div class="ttc" id="namespacearm__compute_xhtml_a40e33693e83cee949a89811e7dabbd3c"><div class="ttname"><a href="namespacearm__compute.xhtml#a40e33693e83cee949a89811e7dabbd3c">arm_compute::validate_arguments</a></div><div class="ttdeci">Status validate_arguments(const ITensorInfo *input, const ITensorInfo *bias, const ITensorInfo *output, const GEMMLowpOutputStageInfo *output_stage)</div><div class="ttdef"><b>Definition:</b> <a href="_n_e_g_e_m_m_lowp_quantize_down_int32_scale_kernel_8cpp_source.xhtml#l00045">NEGEMMLowpQuantizeDownInt32ScaleKernel.cpp:45</a></div></div>
<div class="ttc" id="arm__compute_2core_2_validate_8h_xhtml_a921b705e9e3e0fe928928447869e62a5"><div class="ttname"><a href="arm__compute_2core_2_validate_8h.xhtml#a921b705e9e3e0fe928928447869e62a5">ARM_COMPUTE_ERROR_ON_NULLPTR</a></div><div class="ttdeci">#define ARM_COMPUTE_ERROR_ON_NULLPTR(...)</div><div class="ttdef"><b>Definition:</b> <a href="arm__compute_2core_2_validate_8h_source.xhtml#l00157">Validate.h:157</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="arm__compute_2core_2_validate_8h_source.xhtml#l00157">ARM_COMPUTE_ERROR_ON_NULLPTR</a>, <a class="el" href="_error_8h_source.xhtml#l00204">ARM_COMPUTE_RETURN_ON_ERROR</a>, <a class="el" href="classarm__compute_1_1misc_1_1_i_cloneable.xhtml#a4d10e5012a872e7f78f2b539b673049d">ICloneable&lt; T &gt;::clone()</a>, and <a class="el" href="_n_e_g_e_m_m_lowp_quantize_down_int32_scale_kernel_8cpp_source.xhtml#l00045">arm_compute::validate_arguments()</a>.</p>

<p class="reference">Referenced by <a class="el" href="_n_e_g_e_m_m_lowp_matrix_multiply_core_8cpp_source.xhtml#l00305">NEGEMMLowpMatrixMultiplyCore::validate()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>src/core/NEON/kernels/<a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8h_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.h</a></li>
<li>src/core/NEON/kernels/<a class="el" href="_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel_8cpp_source.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearm__compute.xhtml">arm_compute</a></li><li class="navelem"><a class="el" href="classarm__compute_1_1_n_e_g_e_m_m_lowp_offset_contribution_output_stage_kernel.xhtml">NEGEMMLowpOffsetContributionOutputStageKernel</a></li>
    <li class="footer">Generated on Tue May 18 2021 16:38:45 for Compute Library by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.15 </li>
  </ul>
</div>
</body>
</html>
